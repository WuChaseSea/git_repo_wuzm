Page label: 9
File name: 2310.06671v2.pdf
text:
Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-Rank Adaptation of Large
Language Models. In ICLR . OpenReview.net.
[15] Ziwei Ji, Zihan Liu, Nayeon Lee, Tiezheng Yu, Bryan Wilie, Min Zeng, and
Pascale Fung. 2023. RHO: Reducing Hallucination in Open-domain Dialogues
with Knowledge Grounding. In ACL (Findings) . Association for Computational
Linguistics, 4504–4522.
[16] Bosung Kim, Taesuk Hong, Youngjoong Ko, and Jungyun Seo. 2020. Multi-Task
Learning for Knowledge Graph Completion with Pre-trained Language Models.InCOLING . International Committee on Computational Linguistics, 1737–1743.
[17] Youwei Liang, Ruiyi Zhang, Li Zhang, and Pengtao Xie. 2023. DrugChat: To-
wards Enabling ChatGPT-Like Capabilities on Drug Molecule Graphs. CoRR
abs/2309.03907 (2023).
[18] Chang Liu and Bo Wu. 2023. Evaluating Large Language Models on Graphs:
Performance Insights and Comparative Analysis. CoRR abs/2308.11224 (2023).
[19] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2023. Visual Instruc-
tion Tuning. CoRR abs/2304.08485 (2023).
[20] Ilya Loshchilov and Frank Hutter. 2019. Decoupled Weight Decay Regularization.
InICLR (Poster) . OpenReview.net.
[21] Xin Lv, Yankai Lin, Yixin Cao, Lei Hou, Juanzi Li, Zhiyuan Liu, Peng Li, and Jie
Zhou. 2022. Do Pre-trained Models Benefit Knowledge Graph Completion? A
Reliable Evaluation and a Reasonable Approach. In ACL (Findings) . Association
for Computational Linguistics, 3570–3581.
[22] Chenyang Lyu, Minghao Wu, Longyue Wang, Xinting Huang, Bingshuai Liu,
Zefeng Du, Shuming Shi, and Zhaopeng Tu. 2023. Macaw-LLM: Multi-Modal
Language Modeling with Image, Audio, Video, and Text Integration. CoRR
abs/2306.09093 (2023).
[23] OpenAI. 2023. GPT-4 Technical Report. CoRR abs/2303.08774 (2023).
[24] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright,
Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray,
John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022. Train-
ing language models to follow instructions with human feedback. In NeurIPS .
[25] Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu.
2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap.
CoRR abs/2306.08302 (2023).
[26] Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan
Huang, Lars Liden, Zhou Yu, Weizhu Chen, and Jianfeng Gao. 2023. Check Your
Facts and Try Again: Improving Large Language Models with External Knowledge
and Automated Feedback. CoRR abs/2302.12813 (2023).