Page label: 6
File name: 2310.06671v2.pdf
text:
manual work to annotate each relation with a prompt, we only
report the results of FB15K-237N shown in the original paper.
For zero-shot reasoning, in addition to measuring with the same
backbone Alpaca, we also test the performance of the GPT-3.5-turbor
which has 175B parameters. For the in-context learning method,
we sample k-shot (k=1,2,4,8) structure-aware demonstrations. Be-
sides, we sample 4 neighborhood triples for each triple to conduct
structure-aware instruction tuning. For KoPA, we employ RotatE
[31] and the score function of structural embedding pre-training
and the embedding dimension is set to 512 and the adapter is a
512√ó4096 linear projection layer.
For KoPA, we employ Alpaca-7B [ 32] as the LLM backbone. Al-
paca is a famous extended version of LLaMA [ 33] model fine-tuned
on instruction-following data. We reproduce the triple classification
results of KGLLaMA [ 41] over two backbones (LLaMA and Alpaca)
to avoid the effect of backbone choice on the results. We name the
two baseline models KGLLaMA and KGAlpaca respectively. For
all the fine-tuning methods (instruction tuning, structure-awareinstruction tuning, and KoPA), we fine-tune Alpaca using LoRA
[14] with rank 64. The number of epochs is searched in {3,4,5}and
the learning rate is tuned in {1ùëí‚àí4,3ùëí‚àí4,5ùëí‚àí4}. We use the AdamW
optimizer [ 20] with a fixed batch size of 12. We conducted all the
experiments with Nvidia A800 GPUs. The structural embedding
pre-training process is efficient and only takes several minutes to
finish. Therefore, the main time cost is caused by the LLM fine-
tuning, which takes several hours for different datasets. (1 hour for
UMLS, 4 hours for CoDeX-S, and 8 hours for FB15K-237N in our
experimental environments).
5.1.4 Evaluation Protocol .We evaluate the methods with the
triple classification task [ 3], which is essentially binary classifica-
tion and all the test datasets are label-balanced. Therefore, we use
accuracy, precision, recall, and F1-score as the evaluation metrics.
5.2 Main Results
The main experiment results of triple classification are shown in Ta-
ble 3. Since precision and recall alone do not give a good response
to the model‚Äôs performance on the classification task, we focus
on accuracy and F1-score. However, to provide a comprehensive
analysis of different models, we also report the precision and re-
call results in the table. Overall, we can find that KoPA achieves
outperforming accuracy and F1 results compared with the existing
16 baseline models on all three datasets. Taking CoDeX-S as an
example, KoPA achieves 1.81% improvement in accuracy and 1.85%
improvement on F1. As we use the pre-trained RotatE embeddings
in KoPA, we can observe that KoPA significantly outperforms the