Page label: 3
File name: 2310.06671v2.pdf
text:
the test triple. ZSR is unable to incorporate KG information due to
its setting limitations, otherwise, it cannot be called zero-shot.
As another training-free paradigm, in-context learning (ICL) [ 9]
allows the modelMto add auxiliary demonstration Uto the input
Sand accomplish the task in the form of analogical reasoning,
which can be denoted as:
A𝑖𝑐𝑙=arg max
A𝑃M(A|S𝑖𝑐𝑙)
=arg max
A𝑃M(A|I𝑖𝑐𝑙,U,X)(2)
As for the triple classification task, the demonstration Ushould
be some triples and their labels in the form of {(X𝑖,𝑦𝑖),1≤𝑖≤𝑘},
whereX𝑖is the demonstration triple and 𝑦𝑖is the label. We denote
the ICL with 𝑘demonstrations as 𝑘-shot ICL.
The demonstration triples can be randomly sampled from the
existing training KG. However, to further incorporate the relative
KG information of the test triple (ℎ,𝑟,𝑡), we propose to sample
triples that are in the local structure of ℎand𝑡, which means one
of the entities in each sampled triple should be ℎor𝑡. Besides, as
existing KG only consists of positive triples, we employ negative
sampling [ 21] to sample negative triples for demonstration. The
number of positive and negative triples are the same for balanced
predictions. In the demonstration prompt, the positive triples are
labeled as true and the negative triples are labeled as false.
By doing this, we incorporate the local structural information
into the demonstration prompt Uwith both positive and nega-
tive samples. Such a structure-aware demonstration could better
enhance the analogical reasoning process of the model M.
3.2.2 Instruction tuning approaches .Instruction tuning ap-
proaches fine-tune the LLMs with instruction template to activate
the instruction following ability of LLMs. Vanilla instruction tun-
ing leverages the input S𝑖𝑡to fine-tune LLMs. The instruction
promptI𝑖𝑡will describe the details of completing the triple classi-
fication task and the triple prompt Xconsists of the input triple.