Page label: 3
File name: 2310.06671v2.pdf
text:
the test triple. ZSR is unable to incorporate KG information due to
its setting limitations, otherwise, it cannot be called zero-shot.
As another training-free paradigm, in-context learning (ICL) [ 9]
allows the modelMto add auxiliary demonstration Uto the input
Sand accomplish the task in the form of analogical reasoning,
which can be denoted as:
Ağ‘–ğ‘ğ‘™=arg max
Ağ‘ƒM(A|Sğ‘–ğ‘ğ‘™)
=arg max
Ağ‘ƒM(A|Iğ‘–ğ‘ğ‘™,U,X)(2)
As for the triple classification task, the demonstration Ushould
be some triples and their labels in the form of {(Xğ‘–,ğ‘¦ğ‘–),1â‰¤ğ‘–â‰¤ğ‘˜},
whereXğ‘–is the demonstration triple and ğ‘¦ğ‘–is the label. We denote
the ICL with ğ‘˜demonstrations as ğ‘˜-shot ICL.
The demonstration triples can be randomly sampled from the
existing training KG. However, to further incorporate the relative
KG information of the test triple (â„,ğ‘Ÿ,ğ‘¡), we propose to sample
triples that are in the local structure of â„andğ‘¡, which means one
of the entities in each sampled triple should be â„orğ‘¡. Besides, as
existing KG only consists of positive triples, we employ negative
sampling [ 21] to sample negative triples for demonstration. The
number of positive and negative triples are the same for balanced
predictions. In the demonstration prompt, the positive triples are
labeled as true and the negative triples are labeled as false.
By doing this, we incorporate the local structural information
into the demonstration prompt Uwith both positive and nega-
tive samples. Such a structure-aware demonstration could better
enhance the analogical reasoning process of the model M.
3.2.2 Instruction tuning approaches .Instruction tuning ap-
proaches fine-tune the LLMs with instruction template to activate
the instruction following ability of LLMs. Vanilla instruction tun-
ing leverages the input Sğ‘–ğ‘¡to fine-tune LLMs. The instruction
promptIğ‘–ğ‘¡will describe the details of completing the triple classi-
fication task and the triple prompt Xconsists of the input triple.