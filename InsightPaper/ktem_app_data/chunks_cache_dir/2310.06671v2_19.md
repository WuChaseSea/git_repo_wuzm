Page label: 8
File name: 2310.06671v2.pdf
text:
triple classification task.
CSClinicalHumanity
EconomicsPolitics
KnowPATNonePROAFTRRHFSocial Science
STEMOtherAverage
NoneUMLSCoDeXFB15K-237NFigure 5: The common ability experiments on MMLU.
5.6 Common Ability Retention
To delve into the preservation of generic capabilities in LLMs, we
conducted another experiment to assess the overall proficiency of
LLMs both before and after fine-tuning. We apply the MMLU [ 12]
benchmark for this problem. MMLU is the most popular bench-
mark to evaluate the general abilities of LLMs in different domains
such as Humanities, Social Sciences, STEM, and others. The overall
evaluation results on different datasets are shown in Figure 5:
From the results, it can be noticed that after KoPA training, there
were discernible alterations in the generalized abilities of LLMs.
In most instances, there was a decrease, but notably, STEM profi-
ciency exhibited improvement on the UMLS dataset. We attribute
this phenomenon to the UMLS being a medical KG, encompassing
substantial knowledge in medicine, biology, and chemistry, and
training on this dataset allows the model to acquire more STEM
knowledge. Consequently, when facing natural language inputs
differing from the training task, the model adeptly leverages the
acquired knowledge from KGC task fine-tuning to get enhanced
results. We have listed several subjects in MMLUs that showed
improvement after training with UMLS. These subjects are highly
relevant and close to the knowledge domain encapsulated in the
UMLS in Table 5. The LLMs trained with the KGC task also achieved
significant improvements across different input prompts, marking
a compelling observation.
Table 5: The specific domains in MMLU in which LLM
achieves higher scores after training on UMLS.
Subjects w/o Training w/ Training
Clinical 44.9 47.9 (+3.0%)
College
Medicine30.1 31.2 (+1.1%)
High School
Biology42.9 46.8 (+3.9%)
High School
Chemistry30.0 32.0 (+2.0%)
Medical
Genetics44.0 48.0 (+4.0%)